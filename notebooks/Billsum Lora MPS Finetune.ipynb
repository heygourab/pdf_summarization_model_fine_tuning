{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b37ddabf",
   "metadata": {},
   "source": [
    "# Fine-tuning Flan-T5-base for Legal Document Summarization\n",
    "\n",
    "This notebook is a modified version of the original notebook by Gourab S. (@heygourab).\n",
    "Author: Gourab S. (@heygourab)\n",
    "This notebook demonstrates fine-tuning the Flan-T5-base model on the BillSum dataset using LoRA (Low-Rank Adaptation). We'll use the Hugging Face ecosystem (`transformers`, `datasets`, `peft`) for efficient fine-tuning.\n",
    "\n",
    "## Setup Overview\n",
    "\n",
    "- Base Model: google/flan-t5-base\n",
    "- Dataset: BillSum (~2000 samples)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook assumes a Colab environment with a GPU available. If you're running this locally, make sure to install the required packages and set up your GPU environment accordingly.\n",
    "[Open in Colab](https://colab.research.google.com/github/heygourab/pdf_summarization_model_fine_tuning/blob/main/notebooks/billsum_lora_finetune_colab.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4d2ae",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's install the required dependencies and set up GPU monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6b71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# M1/M2 Mac Setup for PyTorch with MPS (Metal GPU)\n",
    "%pip install -q torch torchvision torchaudio\n",
    "%pip install -q transformers datasets accelerate evaluate peft nltk wandb omegaconf fsspec pyarrow\n",
    "# Note: bitsandbytes is not supported on M1/M2 Mac with MPS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f3264a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal Performance Shaders) is available! Using MPS for acceleration.\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”¥ Device setup for M1/M2 (Metal Performance Shaders)\n",
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS (Metal Performance Shaders) is available! Using MPS for acceleration.\")\n",
    "        return torch.device('mps')\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"CUDA is available! Using CUDA for acceleration.\")\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"No GPU acceleration available. Using CPU.\")\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a9ea0",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8c4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    TaskType\n",
    ")\n",
    "import wandb\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69578d",
   "metadata": {},
   "source": [
    "## 3. Logger setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c4567e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Logger initialized: train_logger\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Log file created at: /Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/notebooks/logs/training_20250520_004206.log\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Python version: 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Log file created at: /Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/notebooks/logs/training_20250520_004206.log\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Python version: 3.10.17 (main, Apr  8 2025, 12:10:59) [Clang 16.0.0 (clang-1600.0.26.6)]\n"
     ]
    }
   ],
   "source": [
    "def setup_logger(name=\"train_logger\", level=logging.INFO, log_file=None):\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    logger.propagate = False  # Avoid duplicate logs\n",
    "\n",
    "    # Clear existing handlers\n",
    "    if logger.hasHandlers():\n",
    "        logger.handlers.clear()\n",
    "\n",
    "    # Formatter for log messages\n",
    "    formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s â€” %(name)s â€” %(levelname)s â€” %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "\n",
    "    # Console handler setup\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    # File handler setup\n",
    "    if log_file is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        log_dir = os.path.join(os.getcwd(), 'logs')  # Safe fallback to current dir\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        log_file = os.path.join(log_dir, f'training_{timestamp}.log')\n",
    "    else:\n",
    "        log_dir = os.path.dirname(log_file)\n",
    "        if log_dir:\n",
    "            os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    # Log header\n",
    "    logger.info(f\"Logger initialized: {name}\")\n",
    "    logger.info(f\"Log file created at: {os.path.abspath(log_file)}\")\n",
    "    logger.info(f\"Python version: {sys.version}\")\n",
    "\n",
    "    return logger\n",
    "\n",
    "# Use it\n",
    "logger = setup_logger(\"train_logger\", logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d79dc",
   "metadata": {},
   "source": [
    "## 4. Loading the required NLTK libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68fbb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Successfully downloaded NLTK resource: punkt\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Successfully downloaded NLTK resource: punkt_tab\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Successfully downloaded NLTK resource: punkt_tab\n"
     ]
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "for resource in ['punkt', 'punkt_tab']:\n",
    "    try:\n",
    "        nltk.download(resource, quiet=True)\n",
    "        logger.info(f\"Successfully downloaded NLTK resource: {resource}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error downloading {resource}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d615513",
   "metadata": {},
   "source": [
    "## 5. Memory Usage Monitoring\n",
    "\n",
    "The `print_memory_usage()` function monitors system resource utilization during model training:\n",
    "\n",
    "- Tracks RAM usage by getting the Resident Set Size (RSS) of current process in GB\n",
    "- For GPU-enabled systems:\n",
    "  - Reports allocated GPU memory\n",
    "  - Shows total available GPU memory\n",
    "  - Calculates percentage of GPU memory utilization\n",
    "  - Resets peak memory tracking statistics\n",
    "\n",
    "This helps identify potential memory bottlenecks and optimize resource usage during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393f44a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” RAM usage: 0.53 GB\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n"
     ]
    }
   ],
   "source": [
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid()) # Get the current process\n",
    "\n",
    "    ram_gb = process.memory_info().rss / 1e9 # Convert bytes to GB\n",
    "    total_gb = psutil.virtual_memory().total / 1e9 # Total system RAM in GB\n",
    "\n",
    "    logger.info(f\"RAM usage: {ram_gb:.2f} GB\") # Current process RAM usage\n",
    "    logger.info(f\"Total system RAM: {total_gb:.2f} GB\") # Total system RAM\n",
    "\n",
    "    # Check for CUDA device\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_mem = torch.cuda.memory_allocated() / 1e9\n",
    "        gpu_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        peak_gpu_mem = torch.cuda.max_memory_allocated() / 1e9\n",
    "\n",
    "        logger.info(f\"GPU memory usage: {gpu_mem:.2f}/{gpu_total:.2f} GB ({gpu_mem/gpu_total*100:.1f}%)\")\n",
    "        logger.info(f\"Peak GPU memory: {peak_gpu_mem:.2f} GB\")\n",
    "\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # Check for MPS device\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # MPS doesn't have built-in memory tracking like CUDA\n",
    "        # We can only log that we're using MPS\n",
    "        logger.info(\"Using MPS (Metal Performance Shaders) - Memory stats not available\")\n",
    "\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9070a4ca",
   "metadata": {},
   "source": [
    "## 6. Configuration Parameters\n",
    "\n",
    "all hyperparameters and configuration settings for the model, dataset, LoRA, and training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” MPS CONFIG:\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   model_name: google/flan-t5-small\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   model_type: encoder-decoder\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   dataset_name: billsum\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   text_col: text\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   summary_col: summary\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   max_input_tokens: 512\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   max_target_tokens: 256\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   sample_size: 400\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   filter_by_length: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   split_train_frac: 0.8\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   prompt_prefix: Summarize the following legal bill: \n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_r: 16\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_alpha: 32\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_target_modules: ['q', 'v', 'k']\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_dropout: 0.05\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_bias: none\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_task_type: SEQ_2_SEQ_LM\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   do_train: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   do_eval: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   num_train_epochs: 3\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   per_device_train_batch_size: 3\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   per_device_eval_batch_size: 2\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gradient_accumulation_steps: 2\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   learning_rate: 5e-05\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   model_name: google/flan-t5-small\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   model_type: encoder-decoder\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   dataset_name: billsum\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   text_col: text\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   summary_col: summary\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   max_input_tokens: 512\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   max_target_tokens: 256\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   sample_size: 400\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   filter_by_length: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   split_train_frac: 0.8\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   prompt_prefix: Summarize the following legal bill: \n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_r: 16\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_alpha: 32\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_target_modules: ['q', 'v', 'k']\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_dropout: 0.05\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_bias: none\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_task_type: SEQ_2_SEQ_LM\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   do_train: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   do_eval: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   num_train_epochs: 3\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   per_device_train_batch_size: 3\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   per_device_eval_batch_size: 2\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gradient_accumulation_steps: 2\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   learning_rate: 5e-05\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   weight_decay: 0.1\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   warmup_steps: 100\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   fp16: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   bf16: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   torch_compile: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gradient_checkpointing: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   optim: adamw_torch\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   logging_steps: 25\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   evaluation_strategy: steps\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   eval_steps: 25\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   save_strategy: steps\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   save_steps: 100\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   save_total_limit: 3\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   load_best_model_at_end: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   metric_for_best_model: rougeL\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   greater_is_better: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   report_to: wandb\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   overwrite_output_dir: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gen_num_beams: 5\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gen_length_penalty: 0.8\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gen_early_stopping: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   seed: 42\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   mount_drive: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   drive_path: MyDrive/ML_models/pdf_summarization\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   training_report_filename: training_report.json\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_adapter_name: lora_billsum_legal\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   output_dir: lora_billsum_legal_20250520_004206\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   weight_decay: 0.1\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   warmup_steps: 100\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   fp16: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   bf16: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   torch_compile: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gradient_checkpointing: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   optim: adamw_torch\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   logging_steps: 25\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   evaluation_strategy: steps\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   eval_steps: 25\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   save_strategy: steps\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   save_steps: 100\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   save_total_limit: 3\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   load_best_model_at_end: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   metric_for_best_model: rougeL\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   greater_is_better: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   report_to: wandb\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   overwrite_output_dir: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gen_num_beams: 5\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gen_length_penalty: 0.8\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   gen_early_stopping: True\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   seed: 42\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   mount_drive: False\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   drive_path: MyDrive/ML_models/pdf_summarization\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   training_report_filename: training_report.json\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   lora_adapter_name: lora_billsum_legal\n",
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€”   output_dir: lora_billsum_legal_20250520_004206\n"
     ]
    }
   ],
   "source": [
    "from peft import TaskType \n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "CONFIG = {\n",
    "    # ====== MODEL & ARCHITECTURE ======\n",
    "    \"model_name\": \"google/flan-t5-small\",  # Lightweight encoder-decoder model\n",
    "    \"model_type\": \"encoder-decoder\",       # Needed for proper Trainer setup\n",
    "\n",
    "    # ====== DATASET CONFIG ======\n",
    "    \"dataset_name\": \"billsum\",\n",
    "    \"text_col\": \"text\",\n",
    "    \"summary_col\": \"summary\",\n",
    "    \"max_input_tokens\": 512,\n",
    "    \"max_target_tokens\": 256,\n",
    "\n",
    "    \"sample_size\": 2000,  # Increased sample size to stabilize training\n",
    "    \"filter_by_length\": True,\n",
    "    \"split_train_frac\": 0.9,  # Give model more data to learn from\n",
    "\n",
    "    # ====== PROMPT INJECTION ======\n",
    "    \"prompt_prefix\": \"Summarize the following legal bill: \",\n",
    "\n",
    "    # ====== LoRA CONFIG ======\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_target_modules\": [\"q\", \"k\", \"v\", \"o\", \"wi\", \"wo\"],  # Cover more layers (T5 specifics)\n",
    "    \"lora_dropout\": 0.1,  # Slightly increased to help generalization\n",
    "    \"lora_bias\": \"none\",\n",
    "    \"lora_task_type\": TaskType.SEQ_2_SEQ_LM,\n",
    "\n",
    "    # ====== TRAINING CONFIG ======\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"num_train_epochs\": 4,  # 3-5 epochs is safe for small datasets\n",
    "    \"per_device_train_batch_size\": 2,  # Lower batch size for stability on MPS\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"gradient_accumulation_steps\": 4,  # Effective batch size = 8\n",
    "\n",
    "    \"learning_rate\": 1e-5,  # Reduced LR to avoid erratic weight updates\n",
    "    \"weight_decay\": 0.01,   # Lower decay to avoid underfitting\n",
    "    \"warmup_steps\": 50,     # Faster warmup for small dataset\n",
    "\n",
    "    \"fp16\": False,  # MPS doesnâ€™t support it\n",
    "    \"bf16\": False,\n",
    "    \"torch_compile\": False,  # Not stable on MPS\n",
    "    \"gradient_checkpointing\": True,  # Saves memory\n",
    "\n",
    "    \"optim\": \"adamw_torch\",  # MPS-safe optimizer\n",
    "\n",
    "    # ====== EVALUATION & LOGGING ======\n",
    "    \"logging_steps\": 10,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 50,  # ðŸ”¥ Slightly slower eval to reduce jitter\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 3,\n",
    "\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"rougeL\",  # Logical for summarization\n",
    "    \"greater_is_better\": True,\n",
    "    \"report_to\": \"wandb\",  # Replace with \"none\" if not using WandB\n",
    "    \"overwrite_output_dir\": True,\n",
    "\n",
    "    # ====== GENERATION CONFIG ======\n",
    "    \"gen_num_beams\": 4,         # Slightly cheaper beam search\n",
    "    \"gen_length_penalty\": 0.8,\n",
    "    \"gen_early_stopping\": True,\n",
    "\n",
    "    # ====== MISC ======\n",
    "    \"seed\": 42,\n",
    "\n",
    "    # ====== GOOGLE DRIVE SUPPORT (COLAB) ======\n",
    "    \"mount_drive\": False,\n",
    "    \"drive_path\": \"MyDrive/ML_models/pdf_summarization\",\n",
    "    \"training_report_filename\": \"training_report.json\",\n",
    "    \"lora_adapter_name\": \"lora_billsum_legal\",\n",
    "}\n",
    "\n",
    "# ====== OUTPUT DIR HANDLER ======\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "CONFIG[\"output_dir\"] = f\"{CONFIG['lora_adapter_name']}_{timestamp}\"\n",
    "\n",
    "if CONFIG[\"mount_drive\"]:\n",
    "    CONFIG[\"gdrive_output_dir\"] = f\"/content/drive/{CONFIG['drive_path']}/{CONFIG['output_dir']}\"\n",
    "\n",
    "# ====== SANITY LOG ======\n",
    "logger.info(\"ðŸ”§ MPS CONFIG DUMP:\")\n",
    "for k, v in CONFIG.items():\n",
    "    logger.info(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0224a",
   "metadata": {},
   "source": [
    "## 6. Login to Hugging Face Hub and Weights & Biases\n",
    "\n",
    "You'll need to log in to Hugging Face to download models/datasets and to Weights & Biases for experiment tracking.\n",
    "You can get your Hugging Face token from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
    "and your W&B API key from [https://wandb.ai/authorize](https://wandb.ai/authorize).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49076cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:06 â€” train_logger â€” INFO â€” Already logged in to Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgoheygourab\u001b[0m (\u001b[33mgoheygourab-self\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.3s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/notebooks/wandb/run-20250520_004207-p4mam4hv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/goheygourab-self/flan-t5-billsum-lora/runs/p4mam4hv' target=\"_blank\">run_20250520_004207</a></strong> to <a href='https://wandb.ai/goheygourab-self/flan-t5-billsum-lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/goheygourab-self/flan-t5-billsum-lora' target=\"_blank\">https://wandb.ai/goheygourab-self/flan-t5-billsum-lora</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/goheygourab-self/flan-t5-billsum-lora/runs/p4mam4hv' target=\"_blank\">https://wandb.ai/goheygourab-self/flan-t5-billsum-lora/runs/p4mam4hv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:09 â€” train_logger â€” INFO â€” Successfully logged in to W&B and initialized experiment.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder, notebook_login\n",
    "\n",
    "try:\n",
    "    if HfFolder.get_token() is None:\n",
    "        logger.info(\"Hugging Face token not found. Please log in.\")\n",
    "        notebook_login()\n",
    "    else:\n",
    "        logger.info(\"Already logged in to Hugging Face Hub.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during Hugging Face login check: {e}\")\n",
    "    logger.info(\"Attempting login...\")\n",
    "    notebook_login()\n",
    "\n",
    "# Login to Weights & Biases\n",
    "try:\n",
    "    wandb.login()\n",
    "    # Use a different run name than output_dir\n",
    "    run_name = f\"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    wandb.init(\n",
    "        project=\"flan-t5-billsum-lora\", \n",
    "        name=run_name,  # Use different run name\n",
    "        config=CONFIG\n",
    "    )\n",
    "    logger.info(\"Successfully logged in to W&B and initialized experiment.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Could not login to W&B: {e}. Ensure you have run `wandb login` or set WANDB_API_KEY.\")\n",
    "    CONFIG[\"report_to\"] = \"tensorboard\" # Fallback to tensorboard\n",
    "    logger.info(\"Falling back to TensorBoard for logging.\")\n",
    "    # No explicit init for tensorboard here, Trainer handles it via TrainingArguments\n",
    "# Note: Use environment variables or notebook secrets to store your tokens securely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e96255",
   "metadata": {},
   "source": [
    "## 7. Mount Google Drive (Optional)\n",
    "\n",
    "If you want to save your model checkpoints and outputs to Google Drive, mount it here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa3daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:09 â€” train_logger â€” INFO â€” Not running in Colab or Google Drive is disabled in the configuration.\n"
     ]
    }
   ],
   "source": [
    "def is_colab():\n",
    "    \"\"\"Check if the current environment is Google Colab.\"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "        \n",
    "if is_colab() and CONFIG[\"mount_drive\"]:\n",
    "    from google.colab import drive\n",
    "    try:\n",
    "        drive.mount('/content/drive')\n",
    "        logger.info(\"Google Drive mounted successfully.\")\n",
    "        # Create the output directory on Drive if it doesn't exist\n",
    "        if not os.path.exists(CONFIG[\"gdrive_output_dir\"]):\n",
    "            os.makedirs(CONFIG[\"gdrive_output_dir\"], exist_ok=True)\n",
    "            logger.info(f\"Created Google Drive output directory: {CONFIG['gdrive_output_dir']}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to mount Google Drive: {e}\")\n",
    "        logger.info(\"Proceeding without Google Drive. Outputs will be saved to Colab ephemeral storage.\")\n",
    "        CONFIG[\"mount_drive\"] = False # Disable drive features if mount fails\n",
    "else:\n",
    "    logger.info(\"Not running in Colab or Google Drive is disabled in the configuration.\")\n",
    "    CONFIG[\"mount_drive\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ed30a",
   "metadata": {},
   "source": [
    "## 8. Load Model, Tokenizer and Configure LoRA\n",
    "\n",
    "Loads the Flan-T5-base model and tokenizer from Hugging Face, configures the model for LoRA training and returns the model and tokenizer objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe80f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” PyTorch version: 2.7.0\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” MPS available: True\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” MPS built: True\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” CUDA available: False\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” Loading tokenizer for model: google/flan-t5-small\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” PyTorch version: 2.7.0\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” MPS available: True\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” MPS built: True\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” CUDA available: False\n",
      "2025-05-20 00:42:13 â€” train_logger â€” INFO â€” Loading tokenizer for model: google/flan-t5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:14 â€” train_logger â€” INFO â€” Tokenizer loaded successfully\n",
      "2025-05-20 00:42:14 â€” train_logger â€” INFO â€” Loading base model: google/flan-t5-small for MPS...\n",
      "2025-05-20 00:42:14 â€” train_logger â€” INFO â€” Loading base model: google/flan-t5-small for MPS...\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Model loaded successfully and moved to mps\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Configuring model for LoRA training...\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Model loaded successfully and moved to mps\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Configuring model for LoRA training...\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” trainable params: 1032192 || all params: 77993344 || trainable%: 1.3234360101292746\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” LoRA adapter applied successfully\n",
      "trainable params: 1,032,192 || all params: 77,993,344 || trainable%: 1.3234\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” RAM usage: 0.32 GB\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” trainable params: 1032192 || all params: 77993344 || trainable%: 1.3234360101292746\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” LoRA adapter applied successfully\n",
      "trainable params: 1,032,192 || all params: 77,993,344 || trainable%: 1.3234\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” RAM usage: 0.32 GB\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:15 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n"
     ]
    }
   ],
   "source": [
    "# Install latest bitsandbytes and required dependencies\n",
    "%pip install -U bitsandbytes --no-cache-dir -q\n",
    "%pip install accelerate --upgrade -q\n",
    "%pip install transformers --upgrade -q\n",
    "\n",
    "# Don't install bitsandbytes on Mac M1 as it's not compatible with MPS\n",
    "\n",
    "# Import required libraries\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# Print versions and available devices \n",
    "def check_environment():\n",
    "    logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "    logger.info(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "    logger.info(f\"MPS built: {torch.backends.mps.is_built()}\")\n",
    "    logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "check_environment()\n",
    "\n",
    "# Function to verify CUDA and bitsandbytes setup\n",
    "def verify_installation():\n",
    "    logger.info(f\"PyTorch version: {torch.__version__}\")\n",
    "    logger.info(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    logger.info(f\"bitsandbytes version: {bnb.__version__}\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"CUDA is not available. 4-bit quantization requires a CUDA-enabled GPU.\")\n",
    "    \n",
    "    # Test BitsAndBytes CUDA kernels\n",
    "    try:\n",
    "        _ = bnb.matmul(torch.zeros(2, 2).cuda(), torch.zeros(2, 2).cuda())\n",
    "        logger.info(\"BitsAndBytes CUDA kernels working correctly\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"BitsAndBytes CUDA test failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Verify installation\n",
    "# verify_installation()\n",
    "\n",
    "# Load tokenizer\n",
    "logger.info(f\"Loading tokenizer for model: {CONFIG['model_name']}\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        CONFIG[\"model_name\"],\n",
    "        use_fast=True,\n",
    "        padding_side=\"right\",\n",
    "        model_max_length=CONFIG[\"max_input_tokens\"]\n",
    "    )\n",
    "    logger.info(\"Tokenizer loaded successfully\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load tokenizer: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load model for MPS\n",
    "logger.info(f\"Loading base model: {CONFIG['model_name']} for MPS...\")\n",
    "try:\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        CONFIG[\"model_name\"],\n",
    "        device_map=None,  # Don't use auto device mapping on MPS\n",
    "        torch_dtype=torch.float32,  # Use FP32 on MPS for better compatibility\n",
    "        use_cache=False  # Disable KV cache to avoid past_key_values warning\n",
    "    )\n",
    "    # Move model to MPS device after loading\n",
    "    if torch.backends.mps.is_available():\n",
    "        model = model.to(device)\n",
    "    logger.info(f\"Model loaded successfully and moved to {device}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Prepare model for training with proper error handling\n",
    "logger.info(\"Configuring model for LoRA training...\")\n",
    "try:\n",
    "    # Configure LoRA for the model\n",
    "    lora_config = LoraConfig(\n",
    "        r=CONFIG[\"lora_r\"],\n",
    "        lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "        target_modules=CONFIG[\"lora_target_modules\"],\n",
    "        lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "        bias=CONFIG[\"lora_bias\"],\n",
    "        task_type=CONFIG[\"lora_task_type\"],\n",
    "    )\n",
    "    \n",
    "    # Enable gradients before applying LoRA\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    # Explicitly verify trainable parameters\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    logger.info(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n",
    "    \n",
    "    logger.info(\"LoRA adapter applied successfully\")\n",
    "    model.print_trainable_parameters()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to apply LoRA adapter: {e}\")\n",
    "    raise\n",
    "\n",
    "# Show memory usage\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15b44bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSeq2SeqLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): T5ForConditionalGeneration(\n",
       "      (shared): Embedding(32128, 512)\n",
       "      (encoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32128, 512)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 6)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-7): 7 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (decoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32128, 512)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 6)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-7): 7 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (k): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=512, out_features=384, bias=False)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=512, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseGatedActDense(\n",
       "                  (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "                  (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): NewGELUActivation()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673f4b4",
   "metadata": {},
   "source": [
    "## 9. Load and Preprocess Dataset\n",
    "\n",
    "Load the BillSum dataset, preprocess it for Flan-T5, and split into training and evaluation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd47db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = \" \".join(text.split())\n",
    "    # Only strip metadata if required\n",
    "    text = re.sub(r'\\s*\\([^\\)]{0,40}\\)\\s*', ' ', text)  # remove very short inlines\n",
    "    text = re.sub(r'\\s*\\[[^\\]]{0,40}\\]\\s*', ' ', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    try:\n",
    "        input_texts = examples.get(CONFIG[\"text_col\"], [])\n",
    "        summary_texts = examples.get(CONFIG[\"summary_col\"], [])\n",
    "\n",
    "        if not input_texts:\n",
    "            raise ValueError(\"Empty input text\")\n",
    "\n",
    "        cleaned_inputs = [clean_text(doc) for doc in input_texts]\n",
    "\n",
    "        prompts = [f'{CONFIG[\"prompt_prefix\"]}{doc}' for doc in cleaned_inputs]\n",
    "\n",
    "        print(f\"Raw: {input_texts[0][:150]}...\")\n",
    "        print(f\"Cleaned: {cleaned_inputs[0][:150]}...\")\n",
    "\n",
    "        model_inputs = tokenizer(\n",
    "            prompts,\n",
    "            max_length=CONFIG[\"max_input_tokens\"] - 32,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        # Use plain summaries â€” no extra formatting\n",
    "        summaries = [s if s else \"No summary provided.\" for s in summary_texts]\n",
    "\n",
    "        labels = tokenizer(\n",
    "            summaries,\n",
    "            max_length=CONFIG[\"max_target_tokens\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Preprocessing failed: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b54f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:15 â€” train_logger â€” WARNING â€” Attempting to update some libraries.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "2025-05-20 00:42:18 â€” train_logger â€” WARNING â€” Library update attempts finished. If issues persist, ensure runtime was restarted after updates.\n",
      "2025-05-20 00:42:18 â€” train_logger â€” INFO â€” Starting dataset loading and processing for: billsum\n",
      "2025-05-20 00:42:18 â€” train_logger â€” INFO â€” Loading dataset with streaming=False and split sample size: 400\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "2025-05-20 00:42:18 â€” train_logger â€” WARNING â€” Library update attempts finished. If issues persist, ensure runtime was restarted after updates.\n",
      "2025-05-20 00:42:18 â€” train_logger â€” INFO â€” Starting dataset loading and processing for: billsum\n",
      "2025-05-20 00:42:18 â€” train_logger â€” INFO â€” Loading dataset with streaming=False and split sample size: 400\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Dataset loaded successfully with streaming=False\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Dataset loaded. Original columns: ['text', 'summary', 'title']\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Number of samples in loaded dataset: 400\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Renamed dataset column: 'text' -> 'article'\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Updated CONFIG['text_col'] to 'article'\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Creating dataset splits...\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Total dataset size for splitting: 400\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Dataset loaded successfully with streaming=False\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Dataset loaded. Original columns: ['text', 'summary', 'title']\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Number of samples in loaded dataset: 400\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Renamed dataset column: 'text' -> 'article'\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Updated CONFIG['text_col'] to 'article'\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Creating dataset splits...\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Total dataset size for splitting: 400\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Created splits - Train: 320, Eval: 80\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Processing datasets (tokenization, etc.)...\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Created splits - Train: 320, Eval: 80\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Processing datasets (tokenization, etc.)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dc4dc07fe04aec9c9e0b8d010948d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: SECTION 1. SHORT TITLE.\n",
      "\n",
      "    This Act may be cited as the ``Bangladeshi Adjustment Act''.\n",
      "\n",
      "SEC. 2. ADJUSTMENT OF STATUS FOR CERTAIN NATIONALS OF BANGL...\n",
      "Cleaned: SECTION 1. SHORT TITLE. This Act may be cited as the ``Bangladeshi Adjustment Act''. SEC. 2. ADJUSTMENT OF STATUS FOR CERTAIN NATIONALS OF BANGLADESH....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2bf5577e164ea89a14bade6e688178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: SECTION 1. SHORT TITLE.\n",
      "\n",
      "    This Act may be cited as the ``Native American Indian Education \n",
      "Act''.\n",
      "\n",
      "SEC. 2. PURPOSE.\n",
      "\n",
      "    It is the purpose of this ...\n",
      "Cleaned: SECTION 1. SHORT TITLE. This Act may be cited as the ``Native American Indian Education Act''. SEC. 2. PURPOSE. It is the purpose of this Act to ensur...\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Dataset processing complete.\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Final tokenized dataset sizes - Training samples: 320, Evaluation samples: 80\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Final tokenized dataset sizes - Training samples: 320, Evaluation samples: 80\n"
     ]
    }
   ],
   "source": [
    "logger.warning(\"Attempting to update some libraries.\")\n",
    "%pip install datasets --upgrade -q\n",
    "%pip install fsspec --upgrade -q\n",
    "%pip install pyarrow --upgrade -q\n",
    "logger.warning(\"Library update attempts finished. If issues persist, ensure runtime was restarted after updates.\")\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "logger.info(f\"Starting dataset loading and processing for: {CONFIG['dataset_name']}\")\n",
    "\n",
    "dataset = None\n",
    "load_dataset_kwargs = {\n",
    "    \"path\": CONFIG[\"dataset_name\"],\n",
    "    \"split\": f\"train[:{CONFIG['sample_size']}]\",\n",
    "}\n",
    "\n",
    "try:\n",
    "    logger.info(f\"Loading dataset with streaming=False and split sample size: {CONFIG['sample_size']}\")\n",
    "    dataset = load_dataset(\n",
    "        **load_dataset_kwargs,\n",
    "    )\n",
    "    logger.info(\"Dataset loaded successfully with streaming=False\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.warning(f\"Attempt 1 failed: {str(e)}\")\n",
    "    logger.info(\"Attempting alternative loading method using pandas...\")\n",
    "    try:\n",
    "        # Define splits and paths\n",
    "        splits = {\n",
    "            'train': 'data/train-00000-of-00001.parquet',\n",
    "            'test': 'data/test-00000-of-00001.parquet',\n",
    "            'ca_test': 'data/ca_test-00000-of-00001.parquet'\n",
    "        }\n",
    "        \n",
    "        # Load training data using pandas\n",
    "        df = pd.read_parquet(f\"hf://datasets/FiscalNote/billsum/{splits['train']}\")\n",
    "        \n",
    "        # Convert to Dataset format\n",
    "        from datasets import Dataset\n",
    "        dataset = Dataset.from_pandas(df)\n",
    "        \n",
    "        # Sample if needed\n",
    "        if CONFIG['sample_size'] and CONFIG['sample_size'] < len(dataset):\n",
    "            dataset = dataset.shuffle(seed=CONFIG['seed']).select(range(CONFIG['sample_size']))\n",
    "            \n",
    "        logger.info(\"Dataset loaded successfully using pandas alternative method\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        logger.error(f\"Alternative loading method also failed: {str(e2)}\")\n",
    "        raise RuntimeError(f\"Both loading methods failed. Original error: {str(e)}, Alternative error: {str(e2)}\")\n",
    "        \n",
    "if dataset is None:\n",
    "    logger.critical(\"FATAL: Dataset could not be loaded by any implemented method.\")\n",
    "    raise RuntimeError(\"Dataset loading failed. Please check the dataset name and parameters.\")\n",
    "\n",
    "\n",
    "logger.info(f\"Dataset loaded. Original columns: {dataset.column_names}\")\n",
    "logger.info(f\"Number of samples in loaded dataset: {len(dataset)}\")\n",
    "\n",
    "if 'text' in dataset.column_names:\n",
    "    dataset = dataset.rename_column('text', 'article')\n",
    "    logger.info(\"Renamed dataset column: 'text' -> 'article'\")\n",
    "    CONFIG['text_col'] = 'article'\n",
    "    logger.info(f\"Updated CONFIG['text_col'] to '{CONFIG['text_col']}'\")\n",
    "else:\n",
    "    logger.warning(f\"'text' column not found in dataset columns: {dataset.column_names}. Skipping rename. Current text column in CONFIG: {CONFIG['text_col']}\")\n",
    "\n",
    "logger.info(\"Creating dataset splits...\")\n",
    "try:\n",
    "    total_size = len(dataset)\n",
    "    logger.info(f\"Total dataset size for splitting: {total_size}\")\n",
    "\n",
    "    train_size = int(total_size * CONFIG[\"split_train_frac\"])\n",
    "    eval_size = total_size - train_size\n",
    "\n",
    "    if train_size <= 0 or eval_size <= 0:\n",
    "        logger.error(f\"Calculated train_size ({train_size}) or eval_size ({eval_size}) is non-positive. Aborting split.\")\n",
    "        raise ValueError(\"Train or evaluation set size is not positive. Check dataset size and split_train_frac.\")\n",
    "\n",
    "    dataset_shuffled = dataset.shuffle(seed=CONFIG[\"seed\"]) # Shuffle before selecting\n",
    "    train_dataset = dataset_shuffled.select(range(train_size))\n",
    "    eval_dataset = dataset_shuffled.select(range(train_size, total_size))\n",
    "\n",
    "    logger.info(f\"Created splits - Train: {len(train_dataset)}, Eval: {len(eval_dataset)}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating dataset splits: {e}\")\n",
    "    raise\n",
    "\n",
    "logger.info(\"Processing datasets (tokenization, etc.)...\")\n",
    "try:\n",
    "    tokenized_datasets = {\n",
    "        'train': train_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            remove_columns=train_dataset.column_names\n",
    "        ),\n",
    "        'eval': eval_dataset.map(\n",
    "            preprocess_function,\n",
    "            batched=True,\n",
    "            remove_columns=eval_dataset.column_names\n",
    "        )\n",
    "    }\n",
    "    logger.info(\"Dataset processing complete.\")\n",
    "    logger.info(f\"Final tokenized dataset sizes - Training samples: {len(tokenized_datasets['train'])}, Evaluation samples: {len(tokenized_datasets['eval'])}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error processing datasets: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a9f58",
   "metadata": {},
   "source": [
    "## 10. Define Training Arguments\n",
    "\n",
    "Configure the training process using Seq2SeqTrainingArguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85dd1a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Training arguments configured for MPS\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=CONFIG[\"output_dir\"],\n",
    "    num_train_epochs=CONFIG[\"num_train_epochs\"],\n",
    "    per_device_train_batch_size=CONFIG[\"per_device_train_batch_size\"],\n",
    "    per_device_eval_batch_size=CONFIG[\"per_device_eval_batch_size\"],\n",
    "    gradient_accumulation_steps=CONFIG[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    weight_decay=CONFIG[\"weight_decay\"],\n",
    "    warmup_steps=CONFIG[\"warmup_steps\"],\n",
    "    \n",
    "    # Optimization - modified for MPS\n",
    "    fp16=False,  # Disable FP16 for MPS\n",
    "    fp16_full_eval=False,\n",
    "    bf16=False,\n",
    "    optim=\"adamw_torch\",  # Use adamw_torch optimizer\n",
    "    \n",
    "    # Disable features that might cause issues on MPS\n",
    "    gradient_checkpointing=False,  # Disable gradient checkpointing on MPS\n",
    "    group_by_length=False,  # Disable length batching\n",
    "    dataloader_pin_memory=False,  # Disable pin_memory on MPS\n",
    "    \n",
    "    # Logging & Evaluation\n",
    "    logging_dir=f\"{CONFIG['output_dir']}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=CONFIG[\"logging_steps\"],\n",
    "    eval_strategy=CONFIG[\"evaluation_strategy\"],\n",
    "    eval_steps=CONFIG[\"eval_steps\"],\n",
    "    \n",
    "    # Saving\n",
    "    save_strategy=CONFIG[\"save_strategy\"],\n",
    "    save_steps=CONFIG[\"save_steps\"],\n",
    "    save_total_limit=CONFIG[\"save_total_limit\"],\n",
    "    \n",
    "    # Model Loading\n",
    "    load_best_model_at_end=CONFIG[\"load_best_model_at_end\"],\n",
    "    metric_for_best_model=CONFIG[\"metric_for_best_model\"],\n",
    "    greater_is_better=CONFIG[\"greater_is_better\"],\n",
    "    \n",
    "    # Generation\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=CONFIG[\"max_target_tokens\"],\n",
    "    generation_num_beams=CONFIG[\"gen_num_beams\"],\n",
    "    \n",
    "    # Other\n",
    "    report_to=CONFIG[\"report_to\"],\n",
    "    seed=CONFIG[\"seed\"],\n",
    "    remove_unused_columns=False,  # Keep all columns\n",
    "    overwrite_output_dir=CONFIG[\"overwrite_output_dir\"],\n",
    "    use_legacy_prediction_loop=True,  # Use legacy prediction loop to avoid past_key_values warning\n",
    ")\n",
    "\n",
    "logger.info(f\"Training arguments configured for MPS\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78898be",
   "metadata": {},
   "source": [
    "## 11. Define Metrics Computation\n",
    "\n",
    "Function to compute ROUGE and BLEU scores for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4970687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Enhanced metrics computation function defined.\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "import numpy as np\n",
    "import nltk\n",
    "from typing import Dict, List\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_metrics():\n",
    "    \"\"\"Load and cache evaluation metrics.\"\"\"\n",
    "    return {\n",
    "        \"rouge\": evaluate.load(\"rouge\"),\n",
    "        \"bleu\": evaluate.load(\"bleu\"),\n",
    "        \"bertscore\": evaluate.load(\"bertscore\")\n",
    "    }\n",
    "\n",
    "def process_texts(texts: List[str]) -> List[str]:\n",
    "    \"\"\"Clean and process texts for evaluation.\"\"\"\n",
    "    return [\"\\n\".join(nltk.sent_tokenize(text.strip())) for text in texts]\n",
    "\n",
    "def compute_metrics(eval_preds, batch_size: int = 32) -> Dict[str, float]:\n",
    "    \"\"\"Compute evaluation metrics with improved error handling and statistics.\"\"\"\n",
    "    try:\n",
    "        metrics = get_metrics()\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        # Decode predictions and labels\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Process texts\n",
    "        decoded_preds = process_texts(decoded_preds)\n",
    "        decoded_labels = process_texts(decoded_labels)\n",
    "\n",
    "        # Compute metrics\n",
    "        rouge_results = metrics[\"rouge\"].compute(\n",
    "            predictions=decoded_preds, \n",
    "            references=decoded_labels\n",
    "        )\n",
    "        \n",
    "        decoded_labels_bleu = [[label] for label in decoded_labels]\n",
    "        bleu_results = metrics[\"bleu\"].compute(\n",
    "            predictions=decoded_preds, \n",
    "            references=decoded_labels_bleu\n",
    "        )\n",
    "\n",
    "        # Compute additional statistics\n",
    "        pred_lengths = [len(p.split()) for p in decoded_preds]\n",
    "        ref_lengths = [len(r.split()) for r in decoded_labels]\n",
    "\n",
    "        results = {\n",
    "            \"rouge1\": rouge_results[\"rouge1\"],\n",
    "            \"rouge2\": rouge_results[\"rouge2\"],\n",
    "            \"rougeL\": rouge_results[\"rougeL\"],\n",
    "            \"rougeLsum\": rouge_results[\"rougeLsum\"],\n",
    "            \"bleu\": bleu_results[\"bleu\"],\n",
    "            \"avg_pred_length\": np.mean(pred_lengths),\n",
    "            \"avg_ref_length\": np.mean(ref_lengths),\n",
    "            \"compression_ratio\": np.mean([p/r for p, r in zip(pred_lengths, ref_lengths)])\n",
    "        }\n",
    "\n",
    "        # Add generation length metric\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        results[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "        return {k: round(v, 4) for k, v in results.items()}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error computing metrics: {e}\")\n",
    "        return {\n",
    "            \"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0,\n",
    "            \"rougeLsum\": 0.0, \"bleu\": 0.0, \"gen_len\": 0,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "logger.info(\"Enhanced metrics computation function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54a510",
   "metadata": {},
   "source": [
    "## 11. Initialize Trainer\n",
    "\n",
    "Set up the `Seq2SeqTrainer` with the model, arguments, datasets, tokenizer, and metrics function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "601cfed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” RAM usage: 0.90 GB\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Data collator initialized successfully\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n",
      "2025-05-20 00:42:34 â€” train_logger â€” INFO â€” Data collator initialized successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/db9plr7n08g67qlmw3z86x340000gn/T/ipykernel_55680/1412348843.py:52: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Trainer initialized with enhanced monitoring\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” RAM usage: 0.90 GB\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” RAM usage: 0.90 GB\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback,TrainerCallback\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear unused memory before training\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print_memory_usage()\n",
    "\n",
    "class MemoryTrackingCallback(TrainerCallback):\n",
    "    \"\"\"Callback to track memory usage during training\"\"\"\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        if state.global_step % 100 == 0:  # Monitor every 100 steps\n",
    "            print_memory_usage()\n",
    "\n",
    "def validate_training_args(args, model):\n",
    "    \"\"\"Validate training arguments for potential issues\"\"\"\n",
    "    if args.per_device_train_batch_size * args.gradient_accumulation_steps > 32:\n",
    "        logger.warning(\"Total batch size might be too large for available memory\")\n",
    "    \n",
    "    if args.fp16 and not torch.cuda.is_available() and not torch.backends.mps.is_available():\n",
    "        raise ValueError(\"FP16 requires CUDA or MPS\")\n",
    "    \n",
    "    if args.fp16 and torch.backends.mps.is_available():\n",
    "        logger.warning(\"FP16 is not fully supported on MPS. Turning it off.\")\n",
    "        args.fp16 = False\n",
    "        args.fp16_full_eval = False\n",
    "\n",
    "# Clear memory before initialization\n",
    "clear_memory()\n",
    "\n",
    "# Initialize data collator with error handling\n",
    "try:\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=tokenizer.pad_token_id,\n",
    "        pad_to_multiple_of=None  # Changed for MPS compatibility\n",
    "    )\n",
    "    logger.info(\"Data collator initialized successfully\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize data collator: {e}\")\n",
    "    raise\n",
    "\n",
    "# Validate training arguments\n",
    "validate_training_args(training_args, model)\n",
    "\n",
    "# Initialize trainer with enhanced monitoring\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=3),\n",
    "        MemoryTrackingCallback()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger.info(\"Trainer initialized with enhanced monitoring\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d90adf",
   "metadata": {},
   "source": [
    "## 12. Train the Model\n",
    "\n",
    "Start the fine-tuning process. This will take some time depending on the dataset size and hardware. ðŸ¥³\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7fc3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_checkpoint(checkpoint_dir):\n",
    "    \"\"\"Find most recent checkpoint in the directory\"\"\"\n",
    "    checkpoints = [d for d in os.listdir(checkpoint_dir) \n",
    "                  if d.startswith(\"checkpoint-\")]\n",
    "    if not checkpoints:\n",
    "        return None\n",
    "    return os.path.join(checkpoint_dir, \n",
    "                       sorted(checkpoints, key=lambda x: int(x.split(\"-\")[1]))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce148d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Starting training...\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Training Configuration:\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Number of training examples: 320\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Number of validation examples: 80\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Training Epochs: 3\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Batch size: 3\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” Training Configuration:\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Number of training examples: 320\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Number of validation examples: 80\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Training Epochs: 3\n",
      "2025-05-20 00:42:35 â€” train_logger â€” INFO â€” - Batch size: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='159' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 76/159 22:09 < 24:51, 0.06 it/s, Epoch 1.39/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>13.910700</td>\n",
       "      <td>15.827261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Couldn't find a module script at /Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/notebooks/bertscore/bertscore.py. Module 'bertscore' doesn't exist on the Hugging Face Hub either.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>13.954200</td>\n",
       "      <td>15.579007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>out of range integral type conversion attempted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5/40 01:01 < 08:56, 0.07 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:477: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "Using the latest cached version of the module from /Users/gourabsarkar/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--rouge/b01e0accf3bd6dd24839b769a5fda24e14995071570870922c71970b3a6ed886 (last modified on Sat May 17 01:29:41 2025) since it couldn't be found locally at evaluate-metric--rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/gourabsarkar/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--rouge/b01e0accf3bd6dd24839b769a5fda24e14995071570870922c71970b3a6ed886 (last modified on Sat May 17 01:29:41 2025) since it couldn't be found locally at evaluate-metric--rouge, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/gourabsarkar/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bleu/9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76 (last modified on Sat May 17 01:29:55 2025) since it couldn't be found locally at evaluate-metric--bleu, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/gourabsarkar/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bleu/9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76 (last modified on Sat May 17 01:29:55 2025) since it couldn't be found locally at evaluate-metric--bleu, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 00:53:53 â€” train_logger â€” ERROR â€” Error computing metrics: Couldn't find a module script at /Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/notebooks/bertscore/bertscore.py. Module 'bertscore' doesn't exist on the Hugging Face Hub either.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd4f6ba799e4a839a37e6732139dee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 01:04:08 â€” train_logger â€” ERROR â€” Error computing metrics: out of range integral type conversion attempted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:477: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-20 01:06:17 â€” train_logger â€” INFO â€” RAM usage: 0.94 GB\n",
      "2025-05-20 01:06:17 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 01:06:17 â€” train_logger â€” INFO â€” Total system RAM: 8.59 GB\n",
      "2025-05-20 01:06:17 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n",
      "2025-05-20 01:06:17 â€” train_logger â€” INFO â€” Using MPS (Metal Performance Shaders) - Memory stats not available\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Batch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mper_device_train_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Execute training\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Log final metrics\u001b[39;00m\n\u001b[1;32m     23\u001b[0m metrics \u001b[38;5;241m=\u001b[39m train_result\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer.py:2627\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2627\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer.py:3096\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3094\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 3096\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3097\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer.py:3045\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 3045\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3046\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   3048\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:197\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer.py:4154\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4151\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4153\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4154\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4155\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4164\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer.py:4953\u001b[0m, in \u001b[0;36mTrainer.prediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4950\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39meval_dataloader \u001b[38;5;241m=\u001b[39m dataloader\n\u001b[1;32m   4952\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m-> 4953\u001b[0m     loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4954\u001b[0m     main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4955\u001b[0m     inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4956\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4957\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:333\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m summon_full_params_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    327\u001b[0m     FullyShardedDataParallel\u001b[38;5;241m.\u001b[39msummon_full_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, FullyShardedDataParallel)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext()\n\u001b[1;32m    330\u001b[0m )\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m summon_full_params_context:\n\u001b[0;32m--> 333\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39m_from_model_config:\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/peft/peft_model.py:2146\u001b[0m, in \u001b[0;36mPeftModelForSeq2SeqLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2145\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 2146\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:2484\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2484\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2485\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2489\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2490\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2491\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2494\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2495\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2496\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2497\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2503\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2504\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:4016\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   4010\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temporary_reorder_cache(\n\u001b[1;32m   4011\u001b[0m             past_key_values\u001b[38;5;241m=\u001b[39mmodel_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   4012\u001b[0m             beam_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_beam_dim(running_beam_indices[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, cur_len \u001b[38;5;241m-\u001b[39m decoder_prompt_len]),\n\u001b[1;32m   4013\u001b[0m         )\n\u001b[1;32m   4015\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 4016\u001b[0m     this_peer_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrunning_beam_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sent_finished\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_token_hits_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcur_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_prompt_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4028\u001b[0m \u001b[38;5;66;03m# 5. prepare outputs\u001b[39;00m\n\u001b[1;32m   4029\u001b[0m \u001b[38;5;66;03m# Take best beams for each batch (the score is sorted in descending order)\u001b[39;00m\n\u001b[1;32m   4030\u001b[0m sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_beam_dim(sequences[:, :num_return_sequences, :])\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:3620\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search_has_unfinished_sequences\u001b[0;34m(running_beam_scores, beam_scores, is_sent_finished, next_token_hits_stopping_criteria, cur_len, max_length, decoder_prompt_len, early_stopping, length_penalty)\u001b[0m\n\u001b[1;32m   3616\u001b[0m exists_open_beam \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m(torch\u001b[38;5;241m.\u001b[39mall(is_sent_finished) \u001b[38;5;241m&\u001b[39m (early_stopping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m   3618\u001b[0m \u001b[38;5;66;03m# c. Have we hit a stopping criteria with all running sequences and have no way to continue? e.g. we have\u001b[39;00m\n\u001b[1;32m   3619\u001b[0m \u001b[38;5;66;03m# reached `max_length``\u001b[39;00m\n\u001b[0;32m-> 3620\u001b[0m valid_continuations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_token_hits_stopping_criteria\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m improvement_possible \u001b[38;5;241m&\u001b[39m exists_open_beam \u001b[38;5;241m&\u001b[39m valid_continuations\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x164acbd30>> (for post_run_cell), with arguments args (<ExecutionResult object at 164300550, execution_count=19 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 1643022c0, raw_cell=\"logger.info(\"Starting training...\")\n",
      "try:\n",
      "    # Set..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/gourabsarkar/Developer/college_project/pdf_summarization_model_fine_tuning/notebooks/Billsum%20Lora%20MPS%20Finetune.ipynb#X44sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:614\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 614\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:778\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 778\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:293\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/college_project/pdf_summarization_model_fine_tuning/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting training...\")\n",
    "try:\n",
    "    # Setup checkpoint directory\n",
    "    checkpoint_dir = os.path.join(CONFIG[\"output_dir\"], \"checkpoints\")\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Check for existing checkpoint\n",
    "    resume_checkpoint = get_latest_checkpoint(checkpoint_dir)\n",
    "    if resume_checkpoint:\n",
    "        logger.info(f\"Resuming from checkpoint: {resume_checkpoint}\")\n",
    "    \n",
    "    # Print training info\n",
    "    logger.info(\"Training Configuration:\")\n",
    "    logger.info(f\"- Number of training examples: {len(trainer.train_dataset)}\")\n",
    "    logger.info(f\"- Number of validation examples: {len(trainer.eval_dataset)}\")\n",
    "    logger.info(f\"- Training Epochs: {CONFIG['num_train_epochs']}\")\n",
    "    logger.info(f\"- Batch size: {CONFIG['per_device_train_batch_size']}\")\n",
    "    \n",
    "    # Execute training\n",
    "    train_result = trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "    \n",
    "    # Log final metrics\n",
    "    metrics = train_result.metrics\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "    \n",
    "    logger.info(\"Training completed successfully!\")\n",
    "    logger.info(f\"Final Training Loss: {metrics.get('train_loss', 'N/A')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Training failed: {e}\")\n",
    "    if wandb.run:\n",
    "        wandb.log({\"training_error\": str(e)})\n",
    "        wandb.run.finish(exit_code=1)\n",
    "    raise e\n",
    "\n",
    "finally:\n",
    "    print_memory_usage()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0458a99f",
   "metadata": {},
   "source": [
    "## 13. Evaluate the Model\n",
    "\n",
    "Evaluate the fine-tuned model on the evaluation set to get final performance metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log(\"Evaluating model...\")\n",
    "eval_metrics = trainer.evaluate()\n",
    "\n",
    "logger.info(\"Evaluation metrics:\")\n",
    "for key, value in eval_metrics.items():\n",
    "    logger.info(f\"{key}: {value}\")\n",
    "\n",
    "# Log evaluation metrics\n",
    "trainer.log_metrics(\"eval\", eval_metrics)\n",
    "trainer.save_metrics(\"eval\", eval_metrics) # Saves to all_results.json\n",
    "\n",
    "# Prepare the training_report.json\n",
    "training_report = {\n",
    "    \"model_name\": CONFIG[\"model_name\"],\n",
    "    \"dataset_name\": CONFIG[\"dataset_name\"],\n",
    "    \"lora_adapter_name\": CONFIG[\"lora_adapter_name\"],\n",
    "    \"output_directory\": CONFIG[\"output_dir\"],\n",
    "    \"training_arguments\": {k: str(v) if isinstance(v, (torch.device, BitsAndBytesConfig)) else v for k, v in training_args.to_dict().items()}, # Convert non-serializable items\n",
    "    \"train_metrics\": trainer.state.log_history[:-1], # All logged steps except final eval\n",
    "    \"eval_metrics\": eval_metrics,\n",
    "    \"final_training_loss\": trainer.state.log_history[-2].get('loss') if len(trainer.state.log_history) > 1 and 'loss' in trainer.state.log_history[-2] else trainer.state.log_history[-1].get('train_loss', 'N/A')\n",
    "}\n",
    "\n",
    "\n",
    "# Add ROUGE and BLEU from eval_metrics to the top level for easier access\n",
    "for metric_key in [\"eval_rouge1\", \"eval_rouge2\", \"eval_rougeL\", \"eval_bleu\"]:\n",
    "    if metric_key in eval_metrics:\n",
    "        training_report[metric_key.replace(\"eval_\", \"\")] = eval_metrics[metric_key]\n",
    "\n",
    "\n",
    "# Save training_report.json locally\n",
    "report_path = os.path.join(CONFIG[\"output_dir\"], CONFIG[\"training_report_filename\"])\n",
    "with open(report_path, \"w\") as f:\n",
    "    json.dump(training_report, f, indent=4)\n",
    "logger.info(f\"Training report saved to {report_path}\")\n",
    "\n",
    "if wandb.run:\n",
    "    wandb.log(eval_metrics) # Log final eval metrics\n",
    "    wandb.save(report_path) # Save report to W&B artifacts\n",
    "    logger.info(\"Evaluation metrics and report logged to W&B.\")\n",
    "\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305442e8",
   "metadata": {},
   "source": [
    "## 14. Save Model and LoRA Adapter\n",
    "\n",
    "Save the fine-tuned LoRA adapter and the full model if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LoRA adapter\n",
    "lora_adapter_path = os.path.join(CONFIG[\"output_dir\"], CONFIG[\"lora_adapter_name\"])\n",
    "model.save_pretrained(lora_adapter_path) # Saves only the LoRA adapter\n",
    "tokenizer.save_pretrained(lora_adapter_path) # Save tokenizer with adapter\n",
    "logger.info(f\"LoRA adapter and tokenizer saved to {lora_adapter_path}\")\n",
    "\n",
    "# To save the full model (optional, requires more space)\n",
    "# merged_model_path = os.path.join(CONFIG[\"output_dir\"], \"merged_model_flan_t5_base_billsum\")\n",
    "# try:\n",
    "#     # Merge LoRA weights with the base model\n",
    "#     merged_model = model.merge_and_unload()\n",
    "#     merged_model.save_pretrained(merged_model_path)\n",
    "#     tokenizer.save_pretrained(merged_model_path)\n",
    "#     logger.info(f\"Full merged model saved to {merged_model_path}\")\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Could not merge and save full model: {e}. This might happen if the base model is not fully on CPU or due to memory constraints.\")\n",
    "#     logger.info(\"Only the LoRA adapter was saved.\")\n",
    "\n",
    "\n",
    "# If Google Drive is mounted, copy outputs there\n",
    "if CONFIG[\"mount_drive\"] and os.path.exists(CONFIG[\"gdrive_output_dir\"]):\n",
    "    logger.info(f\"Copying outputs to Google Drive: {CONFIG['gdrive_output_dir']}\")\n",
    "    # Copy LoRA adapter\n",
    "    gdrive_lora_path = os.path.join(CONFIG[\"gdrive_output_dir\"], CONFIG[\"lora_adapter_name\"])\n",
    "    if os.path.exists(gdrive_lora_path):\n",
    "        logger.info(f\"Removing existing LoRA adapter from GDrive: {gdrive_lora_path}\")\n",
    "        os.system(f\"rm -rf '{gdrive_lora_path}'\") # Use os.system for `rm -rf`\n",
    "    os.system(f\"cp -r '{lora_adapter_path}' '{CONFIG['gdrive_output_dir']}/'\")\n",
    "    logger.info(f\"LoRA adapter copied to {gdrive_lora_path}\")\n",
    "\n",
    "    # Copy training report\n",
    "    gdrive_report_path = os.path.join(CONFIG[\"gdrive_output_dir\"], CONFIG[\"training_report_filename\"])\n",
    "    os.system(f\"cp '{report_path}' '{gdrive_report_path}'\")\n",
    "    logger.info(f\"Training report copied to {gdrive_report_path}\")\n",
    "\n",
    "    # Copy all_results.json (contains eval metrics)\n",
    "    all_results_path = os.path.join(CONFIG[\"output_dir\"], \"all_results.json\")\n",
    "    if os.path.exists(all_results_path):\n",
    "        gdrive_all_results_path = os.path.join(CONFIG[\"gdrive_output_dir\"], \"all_results.json\")\n",
    "        os.system(f\"cp '{all_results_path}' '{gdrive_all_results_path}'\")\n",
    "        logger.info(f\"all_results.json copied to {gdrive_all_results_path}\")\n",
    "\n",
    "    # If merged model was saved and exists, copy it too\n",
    "    # if 'merged_model' in locals() and os.path.exists(merged_model_path):\n",
    "    #     gdrive_merged_model_path = os.path.join(CONFIG[\"gdrive_output_dir\"], \"merged_model_flan_t5_base_billsum\")\n",
    "    #     if os.path.exists(gdrive_merged_model_path):\n",
    "    #         logger.info(f\"Removing existing merged model from GDrive: {gdrive_merged_model_path}\")\n",
    "    #         os.system(f\"rm -rf '{gdrive_merged_model_path}'\")\n",
    "    #     os.system(f\"cp -r '{merged_model_path}' '{CONFIG['gdrive_output_dir']}/'\")\n",
    "    #     logger.info(f\"Full merged model copied to {gdrive_merged_model_path}\")\n",
    "else:\n",
    "    logger.warning(\"Google Drive not mounted or GDrive output path does not exist. Outputs saved locally.\")\n",
    "\n",
    "if wandb.run:\n",
    "    # Log LoRA adapter as artifact if desired\n",
    "    # lora_artifact = wandb.Artifact(CONFIG[\"lora_adapter_name\"], type=\"model\")\n",
    "    # lora_artifact.add_dir(lora_adapter_path)\n",
    "    # wandb.log_artifact(lora_artifact)\n",
    "    # logger.info(f\"LoRA adapter logged as W&B artifact: {CONFIG['lora_adapter_name']}\")\n",
    "    wandb.finish()\n",
    "\n",
    "logger.info(\"Script finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5720cd",
   "metadata": {},
   "source": [
    "## Test the model with a sample input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test document - Cybersecurity and Privacy Protection Act\n",
    "test_document = \"\"\"\n",
    "CYBERSECURITY AND PRIVACY PROTECTION ACT OF 2025\n",
    "\n",
    "SECTION 1. SHORT TITLE AND PURPOSE\n",
    "\n",
    "    (a) This Act may be cited as the 'Cybersecurity and Privacy Protection Act of 2025'.\n",
    "    (b) The purpose of this Act is to enhance cybersecurity measures and protect individual privacy in the digital age.\n",
    "\n",
    "SECTION 2. DEFINITIONS\n",
    "\n",
    "In this Act:\n",
    "    (1) 'Personal Data' means any information relating to an identified or identifiable natural person.\n",
    "    (2) 'Data Controller' means any entity that determines the purposes and means of processing personal data.\n",
    "    (3) 'Critical Infrastructure' means systems and assets vital to national security.\n",
    "\n",
    "SECTION 3. CYBERSECURITY REQUIREMENTS\n",
    "\n",
    "    (a) MANDATORY SECURITY MEASURES.â€”\n",
    "        (1) All Data Controllers shall implement:\n",
    "            (A) End-to-end encryption for data transmission\n",
    "            (B) Multi-factor authentication for system access\n",
    "            (C) Regular security audits and vulnerability assessments\n",
    "\n",
    "    (b) INCIDENT REPORTING.â€”\n",
    "        (1) Data Controllers shall report any security breach within 48 hours.\n",
    "        (2) Penalties for non-compliance shall be up to $500,000 per incident.\n",
    "\n",
    "SECTION 4. PRIVACY PROTECTIONS\n",
    "\n",
    "    (a) CONSENT REQUIREMENTS.â€”\n",
    "        (1) Explicit consent required for data collection\n",
    "        (2) Right to access and delete personal data\n",
    "        (3) Annual privacy impact assessments\n",
    "\n",
    "    (b) CHILDREN'S PRIVACY.â€”\n",
    "        (1) Enhanced protections for users under 13\n",
    "        (2) Parental consent requirements\n",
    "\n",
    "SECTION 5. ENFORCEMENT\n",
    "\n",
    "    (a) The Federal Trade Commission shall enforce this Act.\n",
    "    (b) State Attorneys General may bring civil actions.\n",
    "\n",
    "SECTION 6. AUTHORIZATION OF APPROPRIATIONS\n",
    "\n",
    "    There is authorized to be appropriated $275,000,000 for fiscal year 2026 to carry out this Act.\n",
    "\"\"\"\n",
    "\n",
    "# Test the model with the adapter\n",
    "try:\n",
    "    # Load the trained model with LoRA adapter\n",
    "    logger.info(f\"Loading model with LoRA adapter from {lora_adapter_path}...\")\n",
    "    \n",
    "    # Get the device\n",
    "    current_device = get_device()\n",
    "    \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        lora_adapter_path,\n",
    "        torch_dtype=torch.float32  # Use float32 for MPS compatibility\n",
    "    )\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    model.load_adapter(lora_adapter_path, CONFIG[\"lora_adapter_name\"])\n",
    "    model.set_adapter(CONFIG[\"lora_adapter_name\"])\n",
    "    model.eval()\n",
    "    model.to(current_device)  # Move the model to the appropriate device\n",
    "    \n",
    "    # Process the test document\n",
    "    logger.info(\"Tokenizing test document...\")\n",
    "    prompt = f\"{CONFIG['prompt_prefix']}{test_document}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(current_device)\n",
    "    \n",
    "    # Generate summary\n",
    "    logger.info(\"Generating summary...\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_length=CONFIG[\"max_target_tokens\"],\n",
    "            num_beams=CONFIG[\"gen_num_beams\"],\n",
    "            length_penalty=CONFIG[\"gen_length_penalty\"],\n",
    "            early_stopping=CONFIG[\"gen_early_stopping\"]\n",
    "        )\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(\"\\nGenerated Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(summary)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during inference: {e}\")\n",
    "    print(f\"An error occurred during inference: {str(e)}\")\n",
    "\n",
    "print_memory_usage()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
